# Enterprise Challenge - Sprint 4 - Reply

<p align="center">
  <a href="https://www.fiap.com.br/">
    <img src="https://i.imgur.com/2jMLsTa.png" alt="FIAP" width="300">
  </a>
</p>

**Projeto final da disciplina de InteligÃªncia Artificial, em parceria com a Hermes Reply.**

---

## ğŸ‘¨â€ğŸ“ Integrantes

* **AntÃ´nio Ancelmo Neto Barros**
    * **RM:** rm563683
    * **GitHub:** [@AntonioBarros19](https://github.com/AntonioBarros19)
* **Beatriz Pilecarte de Melo**
    * **RM:** rm564952
    * **GitHub:** [@BPilecarte](https://github.com/BPilecarte)
* **Francismar Alves Martins Junior**
    * **RM:** rm562869
    * **GitHub:** [@yggdrasilGit](https://github.com/yggdrasilGit)
* **Matheus Soares Bento da Silva**
    * **RM:** rm565540
    * **GitHub:** [@matheusbento044](https://github.com/matheusbento04)
* **Vitor Eiji Fernandes Teruia**
    * **RM:** rm563683
    * **GitHub:** [@Vitor985-hub](https://github.com/Vitor985-hub)

## ğŸ‘©â€ğŸ« Professores

* **Tutor:** Leonardo Ruiz Orabona
* **Coordenador:** AndrÃ© Godoi Chiovato

---

## ğŸ“œ DescriÃ§Ã£o do Projeto

Este projeto implementa um MVP (Minimum Viable Product) de um **pipeline de dados fim-a-fim**, simulando um cenÃ¡rio de monitoramento na IndÃºstria 4.0. O fluxo consolida as etapas de arquitetura, coleta, armazenamento, modelagem e visualizaÃ§Ã£o de dados, demonstrando uma soluÃ§Ã£o integrada e funcional.

O objetivo Ã© transformar os dados brutos gerados por sensores em insights acionÃ¡veis, exibidos em um dashboard com mÃ©tricas de desempenho e um sistema de alertas para detecÃ§Ã£o de anomalias, como picos de temperatura em um maquinÃ¡rio industrial.

---

## ğŸ›ï¸ Arquitetura da SoluÃ§Ã£o

A arquitetura do sistema foi desenhada para ser modular e escalÃ¡vel, representando o fluxo completo de dados desde a origem atÃ© a camada de apresentaÃ§Ã£o.

![Arquitetura da SoluÃ§Ã£o](docs/arquitetura/arquitetura-final.png)

*O arquivo editÃ¡vel do diagrama (`.drawio`) estÃ¡ disponÃ­vel no diretÃ³rio `/docs/arquitetura/`.*

---

## ğŸ“ Estrutura do RepositÃ³rio

O projeto estÃ¡ organizado na seguinte estrutura de pastas, conforme os requisitos da entrega:

```
.
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ arquitetura/      # Diagrama da arquitetura da soluÃ§Ã£o
â”œâ”€â”€ ingest/               # CÃ³digo e dados da simulaÃ§Ã£o do sensor ESP32
â”œâ”€â”€ db/                   # Scripts SQL para criaÃ§Ã£o e carga do banco de dados
â”œâ”€â”€ ml/                   # Notebook com o treinamento e avaliaÃ§Ã£o do modelo de ML
â”œâ”€â”€ dashboard/            # AplicaÃ§Ã£o do dashboard com KPIs e alertas
â””â”€â”€ README.md             # Este arquivo
```

---

## ğŸ”§ Ferramentas e Tecnologias

* **SimulaÃ§Ã£o do Sensor:** Wokwi com ESP32 (DHT22)
* **Banco de Dados:** [Preencher com o SGBD escolhido, ex: PostgreSQL, MySQL]
* **Machine Learning:** Python com Scikit-learn, Pandas
* **Dashboard:** Streamlit
* **Versionamento:** Git e GitHub

---

## ğŸš€ Como Executar o Pipeline Completo

Siga os passos abaixo para configurar e executar o projeto em um ambiente local.

**PrÃ©-requisitos:**
* Python 3.8+
* Git
* [Listar outros, como o SGBD que vocÃªs usaram]

**1. Clone o RepositÃ³rio:**
```bash
git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
cd seu-repositorio
```

**2. SimulaÃ§Ã£o e Coleta de Dados:**
A fonte de dados Ã© um sensor de temperatura DHT22 simulado em um ESP32 no Wokwi. As instruÃ§Ãµes detalhadas estÃ£o no [README da IngestÃ£o](/ingest/esp32/README.md). Os dados brutos gerados para este projeto estÃ£o disponÃ­veis em `/ingest/sample_data.csv`.

**3. ConfiguraÃ§Ã£o do Banco de Dados:**
Primeiro, execute o script para criar as tabelas no seu banco de dados.
```bash
# Exemplo de comando para executar o script SQL
psql -U seu_usuario -d seu_banco < db/schema.sql
```
Em seguida, execute o script Python para carregar os dados do arquivo CSV para o banco.
```bash
# Pode ser necessÃ¡rio instalar dependÃªncias antes
pip install -r requirements.txt 
python db/carga_dados.py
```

**4. Treinamento do Modelo de Machine Learning:**
O modelo de ML Ã© treinado e avaliado em um Jupyter Notebook. Abra e execute todas as cÃ©lulas do arquivo `/ml/treinamento_modelo.ipynb` para treinar o modelo com os dados do banco.

**5. VisualizaÃ§Ã£o no Dashboard:**
Para iniciar o dashboard interativo, execute a aplicaÃ§Ã£o Streamlit:
```bash
cd dashboard
pip install -r requirements.txt
streamlit run app.py
```
Acesse o endereÃ§o local informado no terminal para visualizar os KPIs e o sistema de alertas.

---

## ğŸ¬ VÃ­deo Demonstrativo

Uma demonstraÃ§Ã£o completa do pipeline em funcionamento, desde a geraÃ§Ã£o de dados atÃ© o alerta no dashboard, estÃ¡ disponÃ­vel no link abaixo:

**[â¡ï¸ Link para o seu vÃ­deo de atÃ© 5 minutos no YouTube (nÃ£o listado) aqui]**

---

## ğŸ“‹ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a de AtribuiÃ§Ã£o 4.0 International Creative Commons. Veja a `LICENSE` para mais detalhes.
